# 4dlarve-DLmodel
ACmix+Swin-Transformer
# ACmix-Swin-WGCNA: Integrated Deep Learning Framework for Transcriptomic Phenotype Classification

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **English** | [ä¸­æ–‡](#chinese-readme)

## Overview

ACmix-Swin-WGCNA is an integrated deep learning pipeline that combines **Wasserstein GAN with Gradient Penalty (WGAN-GP)** for data augmentation, **ACmix-Swin hybrid architecture** for phenotype classification, and **Weighted Gene Co-expression Network Analysis (WGCNA)** for biological interpretation. This framework is specifically designed for small-sample transcriptomic studies where traditional deep learning approaches struggle due to the high-dimensionality, low-sample-size (HDLSS) problem.

### Key Features

-  **WGAN-GP Data Augmentation**: Generates high-fidelity synthetic transcriptomic samples with quality filtering
-  **ACmix-Swin Architecture**: Hybrid CNN-Transformer model combining local feature extraction and global dependency modeling
-  **WGCNA Integration**: Python implementation of weighted co-expression network analysis
-  **Comprehensive Visualization**: Automated generation of 15+ publication-quality figures (PDF)
-  **Hub Gene Selection**: Dual-scoring system integrating deep learning importance and network topology
-  **Multi-strategy Augmentation**: Combines WGAN-GP, SMOTE, Gaussian noise, and Mixup
-  **Interpretable Results**: Gene-level importance scores and phenotype-specific biomarkers

### Architecture Diagram

```
Input Data (Gene Expression Matrix)
    â†“
[Feature Selection] â†’ Top N genes by variance/mutual information
    â†“
[WGAN-GP Augmentation] â†’ Synthetic sample generation + Quality filtering
    â†“                      
[Multi-strategy Fusion] â†’ WGAN-GP (30%) + SMOTE (15%) + Noise (35%) + Mixup (20%)
    â†“
[ACmix-Swin Classifier]
    â”œâ”€â”€ Feature Embedding â†’ FC layers with LayerNorm & GELU
    â”œâ”€â”€ ACmix Hybrid Layer
    â”‚   â”œâ”€â”€ Swin Window Attention (Global dependencies)
    â”‚   â””â”€â”€ Depthwise Separable Conv (Local features)
    â”‚   â””â”€â”€ Dynamic weighted fusion (Î± Ã— Attention + Î² Ã— Conv)
    â””â”€â”€ Classification Head â†’ Adaptive pooling + Dropout + FC
    â†“
[WGCNA Network Analysis] â†’ Module detection + Trait correlation
    â†“
[Hub Gene Selection] â†’ Combined scoring (DL + WGCNA)
    â†“
Output: Predictions + Importance scores + Network files + Visualizations
```

---

## Installation

### Requirements

- Python 3.8 or higher
- CUDA-capable GPU (recommended for training acceleration)

### Dependencies

```bash
# Core dependencies
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install numpy pandas scikit-learn scipy matplotlib
pip install openpyxl  # For Excel file export

# Optional but recommended
pip install tensorboard  # For training monitoring
```

### Clone Repository

```bash
git clone https://github.com/yourusername/acmix-swin-wgcna.git
cd acmix-swin-wgcna
```

---

## Quick Start

### Basic Usage

```bash
python acmix_swin_wgcna2.py \
    --expr expression_matrix.csv \
    --samples sample_groups.txt \
    --output ./results
```

### Input File Formats

#### 1. Expression Matrix (`expression_matrix.csv`)
```csv
Gene_ID,Sample1,Sample2,Sample3,...
Gene1,5.23,4.87,6.12,...
Gene2,3.45,3.78,2.91,...
Gene3,7.89,8.23,7.45,...
...
```
- **Rows**: Genes (with gene IDs in first column)
- **Columns**: Samples (with sample names in header)
- **Values**: Gene expression levels (e.g., log2(TPM+1), log2(FPKM+1), normalized counts)

#### 2. Sample Groups (`sample_groups.txt`)
```
Sample1	Drone
Sample2	Queen
Sample3	Worker
Sample4	Drone
...
```
- **Format**: Tab-separated (Sample_ID\tPhenotype)
- **Phenotype**: Must match exactly across samples (e.g., "Drone", "Queen", "Worker")

---

## Advanced Usage

### Custom Model Parameters

```bash
python acmix_swin_wgcna2.py \
    --expr exp.csv \
    --samples samples.txt \
    --output ./results \
    --n_features 100 \              # Number of features to select
    --samples_per_class 50 \        # Target samples per class after augmentation
    --embed_dim 64 \                # Embedding dimension (32, 64, 128)
    --num_heads 4 \                 # Number of attention heads
    --window_size 7 \               # Swin window size
    --dropout 0.3 \                 # Dropout rate
    --lr 1e-4 \                     # Learning rate
    --epochs 300 \                  # Max training epochs
    --patience 50 \                 # Early stopping patience
    --use_mixup \                   # Enable Mixup augmentation
    --mixup_alpha 0.2 \             # Mixup alpha parameter
    --label_smoothing 0.05          # Label smoothing factor
```

### Custom Hub Gene Selection

```bash
# Option 1: Same number of hub genes for all phenotypes
python acmix_swin_wgcna2.py \
    --expr exp.csv \
    --samples samples.txt \
    --n_overall_hub 30 \            # Overall hub genes
    --n_phenotype_hub 15            # Hub genes per phenotype

# Option 2: Different numbers for each phenotype
python acmix_swin_wgcna2.py \
    --expr exp.csv \
    --samples samples.txt \
    --n_overall_hub 30 \
    --n_phenotype_hub "Drone:20,Queen:15,Worker:18"
```

---

## Parameter Reference

### Data Parameters
| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--expr` | str | **Required** | Path to expression matrix CSV file |
| `--samples` | str | None | Path to sample grouping file (tab-separated) |
| `--output` | str | `./output_wgcna` | Output directory path |
| `--n_features` | int | 100 | Number of features to select |

### Augmentation Parameters
| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--samples_per_class` | int | 50 | Target samples per class after augmentation |
| `--gan_epochs` | int | 600 | WGAN-GP training epochs |

### Model Architecture Parameters
| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--embed_dim` | int | 64 | Embedding dimension (recommended: 32, 64, 128) |
| `--num_heads` | int | 4 | Number of attention heads in Swin layer |
| `--window_size` | int | 7 | Window size for Swin attention |
| `--dropout` | float | 0.3 | Dropout rate (0.1-0.6) |

### Training Parameters
| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--epochs` | int | 300 | Maximum training epochs |
| `--batch_size` | int | 16 | Batch size for training |
| `--lr` | float | 1e-4 | Learning rate |
| `--weight_decay` | float | 1e-3 | Weight decay (L2 regularization) |
| `--patience` | int | 50 | Early stopping patience |
| `--use_mixup` | flag | False | Enable Mixup augmentation during training |
| `--mixup_alpha` | float | 0.2 | Mixup alpha parameter |
| `--label_smoothing` | float | 0.05 | Label smoothing factor |

### Hub Gene Parameters
| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--n_overall_hub` | int | 20 | Number of overall hub genes |
| `--n_phenotype_hub` | str/int | 10 | Hub genes per phenotype (e.g., "10" or "Drone:15,Queen:10,Worker:12") |

---

## Output Files

The pipeline generates a comprehensive set of output files organized as follows:

```
./output_wgcna/
â”œâ”€â”€ Input/                              # R visualization input files
â”‚   â”œâ”€â”€ node.xlsx                       # Network nodes
â”‚   â”œâ”€â”€ edge.xlsx                       # Network edges
â”‚   â”œâ”€â”€ layout.xlsx                     # Network layout
â”‚   â”œâ”€â”€ module_correlation_matrix.csv   # Module-module correlation
â”‚   â”œâ”€â”€ module_pvalue_matrix.csv        # Module-module p-values
â”‚   â”œâ”€â”€ module_trait_correlation.csv    # Module-trait correlation
â”‚   â”œâ”€â”€ module_trait_pvalue.csv         # Module-trait p-values
â”‚   â”œâ”€â”€ groups.csv                      # Sample grouping
â”‚   â”œâ”€â”€ metabolite_types.xlsx           # Gene types
â”‚   â””â”€â”€ WGCNA_results.pkl               # Complete WGCNA results
â”‚
â”œâ”€â”€ Visualizations/                     # Publication-quality PDFs
â”‚   â”œâ”€â”€ training_curves.pdf             # Loss and accuracy curves
â”‚   â”œâ”€â”€ wgan_training.pdf               # WGAN-GP training dynamics
â”‚   â”œâ”€â”€ confusion_matrix.pdf            # Classification confusion matrix
â”‚   â”œâ”€â”€ acmix_weights.pdf               # ACmix fusion weights
â”‚   â”œâ”€â”€ augmentation_summary.pdf        # Data augmentation statistics
â”‚   â”œâ”€â”€ data_original.pdf               # Original data PCA
â”‚   â”œâ”€â”€ data_augmented.pdf              # Augmented data PCA
â”‚   â”œâ”€â”€ data_comparison.pdf             # Original vs. augmented comparison
â”‚   â”œâ”€â”€ distance_analysis.pdf           # Intra/inter-class distances
â”‚   â”œâ”€â”€ gene_importance.pdf             # Top gene importance scores
â”‚   â”œâ”€â”€ gene_importance_by_class.pdf    # Class-specific importance
â”‚   â”œâ”€â”€ gene_heatmap.pdf                # Gene contribution heatmap
â”‚   â”œâ”€â”€ wgcna_module_trait.pdf          # Module-trait heatmap
â”‚   â””â”€â”€ wgcna_module_correlation.pdf    # Module correlation network
â”‚
â”œâ”€â”€ Data/                               # CSV data files
â”‚   â”œâ”€â”€ training_history.csv            # Training metrics per epoch
â”‚   â”œâ”€â”€ gene_importance.csv             # Overall gene importance
â”‚   â”œâ”€â”€ gene_importance_by_class.csv    # Phenotype-specific importance
â”‚   â”œâ”€â”€ sample_gene_contribution.csv    # Sample-wise gene contribution
â”‚   â”œâ”€â”€ gene_scores_combined.csv        # Combined DL + WGCNA scores
â”‚   â”œâ”€â”€ predictions.csv                 # Model predictions and probabilities
â”‚   â””â”€â”€ selected_features.csv           # Selected feature list
â”‚
â””â”€â”€ model.pth                           # Trained model weights
```

### Key Output Files Description

#### Network Files (for Cytoscape visualization)
- **node.xlsx**: Node attributes (gene IDs, types, annotations)
- **edge.xlsx**: Edge list with weights (gene-phenotype associations)
- **layout.xlsx**: Pre-computed layout coordinates

#### Gene Importance Files
- **gene_importance.csv**: Overall gene importance scores (gradient Ã— input method)
- **gene_importance_by_class.csv**: Phenotype-specific importance for each gene
- **gene_scores_combined.csv**: Integrated scores (DL importance + WGCNA topology)

#### WGCNA Results
- **module_trait_correlation.csv**: Correlation between gene modules and phenotypes
- **module_correlation_matrix.csv**: Inter-module correlation matrix
- **WGCNA_results.pkl**: Complete WGCNA object (module assignments, eigengenes, etc.)

---

## Methodology

### 1. WGAN-GP Data Augmentation

The pipeline uses Wasserstein GAN with Gradient Penalty to generate synthetic transcriptomic samples that preserve biological correlations while expanding the training set.

**Key Features:**
- **Generator**: 2-layer MLP with conditional embedding (noise_dim=64, hidden_dim=128)
- **Critic**: 3-layer spectral-normalized network with label conditioning
- **Gradient Penalty**: Î»_gp = 10 to enforce Lipschitz constraint
- **Quality Filtering**: Removes synthetic samples with excessive distance from real data

**Training Parameters:**
- Optimizer: Adam (lr=1e-4, Î²=(0.0, 0.9))
- Critic iterations per generator update: 5
- Training epochs: 600

### 2. ACmix-Swin Hybrid Architecture

The classification model integrates convolutional operations and self-attention mechanisms through a novel fusion strategy.

**Architecture Components:**

**(a) Feature Embedding**
```
Input â†’ FC(dim â†’ 2Ã—embed_dim) â†’ LayerNorm â†’ GELU â†’ Dropout â†’ FC(2Ã—embed_dim â†’ embed_dimÃ—window_size)
```

**(b) ACmix Fusion Layer**

Two parallel branches with dynamic weighted fusion:

- **Attention Branch**: Swin Window Attention with relative position bias
  ```
  Attention(Q,K,V) = softmax(QK^T/âˆšd_k + B)V
  ```
  
- **Convolution Branch**: Depthwise Separable Convolution
  ```
  DepthConv(kernel=3) â†’ PointConv(kernel=1) â†’ BatchNorm â†’ GELU
  ```

- **Fusion**: `Output = Î± Ã— Attention_out + Î² Ã— Conv_out`
  - Î± and Î² are learnable parameters (initialized at 0.5)
  - Automatically balances global and local feature extraction

**(c) Classification Head**
```
LayerNorm â†’ AdaptiveAvgPool1d â†’ Dropout(0.3) â†’ FC(embed_dim â†’ num_classes)
```

### 3. WGCNA Network Analysis

Python implementation of weighted gene co-expression network analysis following the WGCNA protocol.

**Pipeline:**
1. **Soft-thresholding**: Select power Î² to approximate scale-free topology (RÂ² > 0.85)
2. **Adjacency Matrix**: `a_ij = |cor(x_i, x_j)|^Î²`
3. **TOM Similarity**: Topological Overlap Matrix for robust similarity
4. **Module Detection**: Hierarchical clustering with dynamic tree cut
5. **Module Eigengenes**: First principal component of module expression
6. **Trait Association**: Correlation between module eigengenes and phenotypes

### 4. Hub Gene Selection

Integrates deep learning importance and network topology through dual scoring:

```
DL_score = Normalized(|âˆ‚Loss/âˆ‚x_i Ã— x_i|)
WGCNA_score = Normalized(max(GS_i) Ã— max(MM_i))
Combined_score = w_DL Ã— DL_score + (1 - w_DL) Ã— WGCNA_score
```

Where:
- **GS** (Gene Significance): Correlation with phenotype
- **MM** (Module Membership): Correlation with module eigengene
- **w_DL**: Weight for deep learning importance (default: 1.0)

**Hub Gene Categories:**
- **Overall Hub**: Top N genes by combined score across all phenotypes
- **Phenotype-specific Hub**: Top M genes for each phenotype based on class-specific DL importance

---

## Training Strategy

### Optimizer and Learning Rate
- **Optimizer**: AdamW (weight_decay=1e-3)
- **Base Learning Rate**: 1e-4
- **Warmup**: Linear warmup for first 10 epochs
- **Scheduler**: Cosine annealing after warmup

### Regularization Techniques
1. **Dropout**: 0.3 in embedding and classification layers
2. **Label Smoothing**: 0.05 (softens one-hot labels)
3. **Mixup Augmentation**: Optional (Î±=0.2)
4. **Gradient Clipping**: max_norm=1.0
5. **Early Stopping**: Patience=50 based on validation loss

### Data Split
- Training : Test = 80% : 20%
- Stratified sampling to maintain class balance

---

## Example Workflow

### 1. Prepare Your Data

```python
import pandas as pd

# Load expression data
expr_df = pd.read_csv('your_expression_data.csv', index_col=0)
# Rows = Genes, Columns = Samples

# Create sample groups file
samples = expr_df.columns.tolist()
groups = ['Drone', 'Queen', 'Worker', ...]  # Your phenotype labels

sample_groups = pd.DataFrame({'Sample': samples, 'Group': groups})
sample_groups.to_csv('sample_groups.txt', sep='\t', index=False, header=False)
```

### 2. Run the Pipeline

```bash
python acmix_swin_wgcna2.py \
    --expr your_expression_data.csv \
    --samples sample_groups.txt \
    --output ./my_results \
    --n_features 150 \
    --samples_per_class 60 \
    --embed_dim 64 \
    --epochs 300 \
    --use_mixup
```

### 3. Visualize Results

The pipeline automatically generates all visualizations in PDF format. For interactive network visualization:

**Option 1: Use Cytoscape**
```r
# In Cytoscape:
# 1. Import network from ./my_results/Input/edge.xlsx
# 2. Import node attributes from ./my_results/Input/node.xlsx
# 3. Apply layout from ./my_results/Input/layout.xlsx
```

**Option 2: Use R visualization script** (if available)
```r
# Place Input/ folder in R script directory
source('visualization_script.R')
```

### 4. Interpret Results

**Key files to examine:**

1. **Model Performance**: `confusion_matrix.pdf`, `training_curves.pdf`
2. **Gene Importance**: `gene_importance.csv`, `gene_importance_by_class.pdf`
3. **Hub Genes**: `gene_scores_combined.csv` (sorted by combined_score)
4. **Module Analysis**: `wgcna_module_trait.pdf`, `module_trait_correlation.csv`
5. **Predictions**: `predictions.csv` (with class probabilities)

---

## Troubleshooting

### Common Issues

**1. Out of Memory Error**
```bash
# Reduce batch size and embedding dimension
--batch_size 8 --embed_dim 32
```

**2. Model Overfitting**
```bash
# Increase dropout and weight decay
--dropout 0.5 --weight_decay 1e-2 --use_mixup
```

**3. Poor Convergence**
```bash
# Try different learning rate and longer warmup
--lr 5e-5 --warmup_epochs 20
```

**4. WGCNA Module Detection Fails**
```bash
# Adjust WGCNA parameters in code:
# min_module_size=10 (increase if too many small modules)
# merge_cut_height=0.25 (decrease for more modules)
```

**5. ImportError: openpyxl**
```bash
pip install openpyxl
# Or the code will automatically fall back to CSV format
```

---

## Performance Benchmarks

### Test Environment
- **Hardware**: NVIDIA RTX 3090 (24GB), Intel i9-12900K
- **Dataset**: 199 samples, 20,000 genes, 3 phenotypes
- **Configuration**: embed_dim=64, window_size=7, 100 selected features

### Runtime
| Stage | Time |
|-------|------|
| Feature Selection | ~5 seconds |
| WGAN-GP Training (600 epochs) | ~3 minutes |
| Data Augmentation | ~10 seconds |
| Model Training (300 epochs) | ~8 minutes |
| WGCNA Analysis | ~2 minutes |
| Visualization | ~30 seconds |
| **Total** | **~14 minutes** |

### Model Performance (Example)
- **Test Accuracy**: 87.6%
- **F1-Score (weighted)**: 0.86
- **Parameters**: ~45,000
- **Inference Time**: <1ms per sample

---

## Citation

If you use this code in your research, please cite:

```bibtex
@software{acmix_swin_wgcna,
  title={ACmix-Swin-WGCNA: Integrated Deep Learning Framework for Transcriptomic Phenotype Classification},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/acmix-swin-wgcna}
}
```

**Key References:**

1. **WGAN-GP**:
   - Arjovsky, M., Chintala, S., & Bottou, L. (2017). Wasserstein generative adversarial networks. In ICML.
   - Gulrajani, I., et al. (2017). Improved training of Wasserstein GANs. In NeurIPS.

2. **ACmix**:
   - Pan, X., et al. (2022). On the integration of self-attention and convolution. In CVPR.

3. **Swin Transformer**:
   - Liu, Z., et al. (2021). Swin transformer: Hierarchical vision transformer using shifted windows. In ICCV.

4. **WGCNA**:
   - Langfelder, P., & Horvath, S. (2008). WGCNA: an R package for weighted correlation network analysis. BMC bioinformatics.

---

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### Development Setup

```bash
git clone https://github.com/yourusername/acmix-swin-wgcna.git
cd acmix-swin-wgcna

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/
```

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## Acknowledgments

- Thanks to the PyTorch team for the excellent deep learning framework
- WGCNA methodology inspired by Peter Langfelder and Steve Horvath
- ACmix architecture based on the work by Pan et al. (2022)
- Special thanks to all contributors and users

---

## Contact

For questions, issues, or collaborations:
- **GitHub Issues**: [https://github.com/yourusername/acmix-swin-wgcna/issues](https://github.com/yourusername/acmix-swin-wgcna/issues)
- **Email**: your.email@institution.edu

---

<a name="chinese-readme"></a>

# ä¸­æ–‡è¯´æ˜æ–‡æ¡£

## æ¦‚è¿°

ACmix-Swin-WGCNA æ˜¯ä¸€ä¸ªæ•´åˆæ·±åº¦å­¦ä¹ çš„è½¬å½•ç»„è¡¨å‹åˆ†ç±»æ¡†æ¶ï¼Œä¸“ä¸ºå°æ ·æœ¬é«˜ç»´ç”Ÿç‰©æ•°æ®è®¾è®¡ã€‚è¯¥å·¥å…·ç»“åˆäº† **WGAN-GP æ•°æ®å¢å¼º**ã€**ACmix-Swin æ··åˆæ¶æ„**å’Œ**åŠ æƒåŸºå› å…±è¡¨è¾¾ç½‘ç»œåˆ†æ(WGCNA)**ï¼Œä¸ºè½¬å½•ç»„ç ”ç©¶æä¾›ä»æ•°æ®é¢„å¤„ç†åˆ°ç”Ÿç‰©å­¦è§£é‡Šçš„å®Œæ•´æµç¨‹ã€‚

### æ ¸å¿ƒç‰¹æ€§

- ğŸ§¬ **WGAN-GP æ•°æ®å¢å¼º**ï¼šç”Ÿæˆé«˜ä¿çœŸåˆæˆæ ·æœ¬ï¼Œç¼“è§£å°æ ·æœ¬é—®é¢˜
- ğŸ¤– **ACmix-Swin æ··åˆæ¶æ„**ï¼šèåˆCNNå±€éƒ¨ç‰¹å¾æå–å’ŒTransformerå…¨å±€ä¾èµ–å»ºæ¨¡
- ğŸ”— **WGCNA ç½‘ç»œåˆ†æ**ï¼šPython å®ç°çš„åŠ æƒå…±è¡¨è¾¾ç½‘ç»œåˆ†æ
- ğŸ“Š **å…¨é¢å¯è§†åŒ–**ï¼šè‡ªåŠ¨ç”Ÿæˆ15+å¼ é«˜è´¨é‡å›¾è¡¨(PDFæ ¼å¼)
- ğŸ¯ **Hub åŸºå› ç­›é€‰**ï¼šæ•´åˆæ·±åº¦å­¦ä¹ é‡è¦æ€§å’Œç½‘ç»œæ‹“æ‰‘çš„åŒé‡è¯„åˆ†
- ğŸ“ˆ **å¤šç­–ç•¥å¢å¼º**ï¼šç»“åˆ WGAN-GPã€SMOTEã€é«˜æ–¯å™ªå£°å’Œ Mixup
- ğŸ”¬ **å¯è§£é‡Šç»“æœ**ï¼šåŸºå› æ°´å¹³é‡è¦æ€§è¯„åˆ†å’Œè¡¨å‹ç‰¹å¼‚æ€§æ ‡å¿—ç‰©

## å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install torch numpy pandas scikit-learn scipy matplotlib openpyxl
```

### åŸºç¡€ç”¨æ³•

```bash
python acmix_swin_wgcna2.py \
    --expr è¡¨è¾¾çŸ©é˜µ.csv \
    --samples æ ·æœ¬åˆ†ç»„.txt \
    --output ./ç»“æœè¾“å‡º
```

### è¾“å…¥æ–‡ä»¶æ ¼å¼

#### è¡¨è¾¾çŸ©é˜µ (CSVæ ¼å¼)
```csv
åŸºå› ID,æ ·æœ¬1,æ ·æœ¬2,æ ·æœ¬3,...
åŸºå› 1,5.23,4.87,6.12,...
åŸºå› 2,3.45,3.78,2.91,...
```

#### æ ·æœ¬åˆ†ç»„ (åˆ¶è¡¨ç¬¦åˆ†éš”)
```
æ ·æœ¬1	å·¥èœ‚
æ ·æœ¬2	èœ‚ç‹
æ ·æœ¬3	é›„èœ‚
```

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æ¨¡å‹å‚æ•°

```bash
python acmix_swin_wgcna2.py \
    --expr è¡¨è¾¾çŸ©é˜µ.csv \
    --samples æ ·æœ¬åˆ†ç»„.txt \
    --output ./ç»“æœ \
    --n_features 100 \              # ç‰¹å¾é€‰æ‹©æ•°é‡
    --samples_per_class 50 \        # æ¯ç±»å¢å¼ºåæ ·æœ¬æ•°
    --embed_dim 64 \                # åµŒå…¥ç»´åº¦
    --num_heads 4 \                 # æ³¨æ„åŠ›å¤´æ•°
    --window_size 7 \               # Swinçª—å£å¤§å°
    --dropout 0.3 \                 # Dropoutç‡
    --lr 1e-4 \                     # å­¦ä¹ ç‡
    --epochs 300 \                  # æœ€å¤§è®­ç»ƒè½®æ•°
    --use_mixup                     # å¯ç”¨Mixupå¢å¼º
```

### è‡ªå®šä¹‰HubåŸºå› æ•°é‡

```bash
# æ–¹å¼1ï¼šç»Ÿä¸€æ•°é‡
--n_overall_hub 30 --n_phenotype_hub 15

# æ–¹å¼2ï¼šåˆ†åˆ«æŒ‡å®š
--n_phenotype_hub "å·¥èœ‚:20,èœ‚ç‹:15,é›„èœ‚:18"
```

## å‚æ•°è¯´æ˜

### æ•°æ®å‚æ•°
- `--expr`: è¡¨è¾¾çŸ©é˜µæ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
- `--samples`: æ ·æœ¬åˆ†ç»„æ–‡ä»¶è·¯å¾„
- `--output`: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š./output_wgcnaï¼‰
- `--n_features`: ç‰¹å¾é€‰æ‹©æ•°é‡ï¼ˆé»˜è®¤ï¼š100ï¼‰

### å¢å¼ºå‚æ•°
- `--samples_per_class`: æ¯ç±»ç›®æ ‡æ ·æœ¬æ•°ï¼ˆé»˜è®¤ï¼š50ï¼‰
- `--gan_epochs`: WGAN-GPè®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ï¼š600ï¼‰

### æ¨¡å‹å‚æ•°
- `--embed_dim`: åµŒå…¥ç»´åº¦ï¼ˆé»˜è®¤ï¼š64ï¼Œå¯é€‰32/64/128ï¼‰
- `--num_heads`: æ³¨æ„åŠ›å¤´æ•°ï¼ˆé»˜è®¤ï¼š4ï¼‰
- `--window_size`: Swinçª—å£å¤§å°ï¼ˆé»˜è®¤ï¼š7ï¼‰
- `--dropout`: Dropoutç‡ï¼ˆé»˜è®¤ï¼š0.3ï¼‰

### è®­ç»ƒå‚æ•°
- `--epochs`: æœ€å¤§è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ï¼š300ï¼‰
- `--batch_size`: æ‰¹å¤§å°ï¼ˆé»˜è®¤ï¼š16ï¼‰
- `--lr`: å­¦ä¹ ç‡ï¼ˆé»˜è®¤ï¼š1e-4ï¼‰
- `--patience`: æ—©åœè€å¿ƒå€¼ï¼ˆé»˜è®¤ï¼š50ï¼‰
- `--use_mixup`: å¯ç”¨Mixupå¢å¼º
- `--label_smoothing`: æ ‡ç­¾å¹³æ»‘ç³»æ•°ï¼ˆé»˜è®¤ï¼š0.05ï¼‰

## è¾“å‡ºæ–‡ä»¶

```
./output_wgcna/
â”œâ”€â”€ Input/                              # Rå¯è§†åŒ–è¾“å…¥æ–‡ä»¶
â”‚   â”œâ”€â”€ node.xlsx                       # ç½‘ç»œèŠ‚ç‚¹
â”‚   â”œâ”€â”€ edge.xlsx                       # ç½‘ç»œè¾¹
â”‚   â”œâ”€â”€ module_trait_correlation.csv    # æ¨¡å—-è¡¨å‹ç›¸å…³æ€§
â”‚   â””â”€â”€ WGCNA_results.pkl               # å®Œæ•´WGCNAç»“æœ
â”‚
â”œâ”€â”€ Visualizations/                     # å¯è§†åŒ–å›¾è¡¨(PDF)
â”‚   â”œâ”€â”€ training_curves.pdf             # è®­ç»ƒæ›²çº¿
â”‚   â”œâ”€â”€ confusion_matrix.pdf            # æ··æ·†çŸ©é˜µ
â”‚   â”œâ”€â”€ gene_importance.pdf             # åŸºå› é‡è¦æ€§
â”‚   â”œâ”€â”€ wgcna_module_trait.pdf          # æ¨¡å—-è¡¨å‹çƒ­å›¾
â”‚   â””â”€â”€ ...ï¼ˆå…±15+å¼ å›¾è¡¨ï¼‰
â”‚
â”œâ”€â”€ Data/                               # æ•°æ®æ–‡ä»¶(CSV)
â”‚   â”œâ”€â”€ gene_importance.csv             # åŸºå› é‡è¦æ€§è¯„åˆ†
â”‚   â”œâ”€â”€ gene_scores_combined.csv        # ç»¼åˆè¯„åˆ†(DL+WGCNA)
â”‚   â”œâ”€â”€ predictions.csv                 # æ¨¡å‹é¢„æµ‹ç»“æœ
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ model.pth                           # è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡
```

## æ–¹æ³•å­¦åŸç†

### 1. WGAN-GP æ•°æ®å¢å¼º
- ä½¿ç”¨Wassersteinè·ç¦»å’Œæ¢¯åº¦æƒ©ç½šè®­ç»ƒç”Ÿæˆå¯¹æŠ—ç½‘ç»œ
- ç”Ÿæˆé«˜ä¿çœŸåˆæˆè½¬å½•ç»„æ ·æœ¬
- è´¨é‡è¿‡æ»¤ç¡®ä¿ç”Ÿæˆæ ·æœ¬çš„ç”Ÿç‰©å­¦åˆç†æ€§

### 2. ACmix-Swin æ··åˆæ¶æ„
- **æ³¨æ„åŠ›åˆ†æ”¯**ï¼šSwinçª—å£æ³¨æ„åŠ›æ•è·å…¨å±€ä¾èµ–
- **å·ç§¯åˆ†æ”¯**ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯æå–å±€éƒ¨ç‰¹å¾
- **åŠ¨æ€èåˆ**ï¼šå¯å­¦ä¹ æƒé‡ Î± å’Œ Î² è‡ªé€‚åº”å¹³è¡¡ä¸¤ä¸ªåˆ†æ”¯

### 3. WGCNA ç½‘ç»œåˆ†æ
- è½¯é˜ˆå€¼é€‰æ‹©
- æ‹“æ‰‘é‡å çŸ©é˜µ(TOM)è®¡ç®—
- æ¨¡å—æ£€æµ‹å’Œç‰¹å¾åŸºå› æå–
- æ¨¡å—-è¡¨å‹å…³è”åˆ†æ

### 4. Hub åŸºå› ç­›é€‰
æ•´åˆæ·±åº¦å­¦ä¹ å’ŒWGCNAçš„åŒé‡è¯„åˆ†ï¼š
```
ç»¼åˆè¯„åˆ† = w_DL Ã— DLé‡è¦æ€§ + (1-w_DL) Ã— WGCNAè¯„åˆ†
```

## æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ
- ç¡¬ä»¶ï¼šNVIDIA RTX 3090, Intel i9-12900K
- æ•°æ®é›†ï¼š199æ ·æœ¬ï¼Œ20000åŸºå› ï¼Œ3è¡¨å‹

### è¿è¡Œæ—¶é—´
- ç‰¹å¾é€‰æ‹©ï¼š~5ç§’
- WGAN-GPè®­ç»ƒï¼š~3åˆ†é’Ÿ
- æ¨¡å‹è®­ç»ƒï¼š~8åˆ†é’Ÿ
- WGCNAåˆ†æï¼š~2åˆ†é’Ÿ
- **æ€»è®¡ï¼š~14åˆ†é’Ÿ**

### æ¨¡å‹æ€§èƒ½ï¼ˆç¤ºä¾‹ï¼‰
- æµ‹è¯•å‡†ç¡®ç‡ï¼š87.6%
- F1åˆ†æ•°ï¼š0.86
- å‚æ•°é‡ï¼š~45,000

## å¸¸è§é—®é¢˜

### å†…å­˜ä¸è¶³
```bash
--batch_size 8 --embed_dim 32
```

### æ¨¡å‹è¿‡æ‹Ÿåˆ
```bash
--dropout 0.5 --weight_decay 1e-2 --use_mixup
```

### æ”¶æ•›å›°éš¾
```bash
--lr 5e-5 --patience 80
```

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬å·¥å…·ï¼Œè¯·å¼•ç”¨ï¼š

è¿˜æœªå‘è¡¨
```

## è”ç³»æ–¹å¼
- Email: surunlang@gmail.com

---

**æ³¨**ï¼šæœ¬å·¥å…·ä»…ä¾›å­¦æœ¯ç ”ç©¶ä½¿ç”¨ã€‚
